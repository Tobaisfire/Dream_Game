{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from brain import network\n",
    "import warnings\n",
    "\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\KEVAL\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = StrOutputParser()\n",
    "\n",
    "\n",
    "llm = network.llm_selection(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm, verbose=True)\n",
    "#chain = model | parser\n",
    "\n",
    "# print(chain.invoke(\"Hello\"))\n",
    "print(parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pdf reader llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def pdf_summarize(query: str):\n",
    "    try:\n",
    "    \n",
    "        file_path = (\n",
    "        f\"D:\\My-projects\\LLM\\Dream_Game\\{query}.pdf\"\n",
    "        )\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        docs = loader.load_and_split()\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    "            )\n",
    "        all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "        chain = load_summarize_chain(llm, chain_type=\"stuff\",verbose=False)\n",
    "\n",
    "        result = chain.invoke(all_splits)\n",
    "\n",
    "        return result[\"output_text\"]\n",
    "    except Exception as E:\n",
    "        return str(E)\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "pdf = StructuredTool.from_function(\n",
    "    func=pdf_summarize,\n",
    "    name=\"Pdf wizard\",\n",
    "    description=\"useful for when you need to summarize a given pdf\",\n",
    "    # coroutine= ... <- you can specify an async method if desired as well\n",
    ")\n",
    "\n",
    "\n",
    "tools =[pdf]\n",
    "\n",
    "print(pdf_summarize(\"Keval_Resume_24\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "#         ),\n",
    "#         MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HumanMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi! I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm bob\u001b[39m\u001b[38;5;124m\"\u001b[39m),AIMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello bob!\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HumanMessage' is not defined"
     ]
    }
   ],
   "source": [
    "history = [HumanMessage(content=\"hi! I'm bob\"),AIMessage(content=\"Hello bob!\")]\n",
    "while True:\n",
    "    user_query = input()\n",
    "    if 'exit' in user_query:\n",
    "        break\n",
    "\n",
    "    history.extend([HumanMessage(content=user_query)])\n",
    "    response = model.invoke(history)\n",
    "    print(response.content)\n",
    "    history.extend([AIMessage(content=response.content)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Pdf wizard(query: str) - useful for when you need to summarize a given pdf\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Pdf wizard]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "# from langchain.agents import create_tool_calling_agent\n",
    "# from langchain.agents import initialize_agent\n",
    "\n",
    "# agent = initialize_agent(tools,\n",
    "#                          llm,\n",
    "#                          agent=\"zero-shot-react-description\",\n",
    "#                          verbose=True)\n",
    "\n",
    "# # agent.agent.llm_chain.prompt.template = \n",
    "\n",
    "\n",
    "# print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
